- 开发建议
  【强制】，【推荐】，【建议】三个级别
- 问题
  索引失效
  1.隐式转换造成的索引失效。
  [MySQL中的隐式转换造成的索引失效](https://javaguide.cn/database/mysql/index-invalidation-caused-by-implicit-conversion.html#%E5%89%8D%E8%A8%80)
- 开发设计规范
  1. 【强制】禁止使用存储过程。
  存储过程难以调试和扩展，更没有可迁移性。
  2. 【建议】避免数据类型的隐式转换
  隐式转换会导致索引失效如: select name,phone from customer where id = '111';
  3.【强制】 建议使用预编译语句进行数据库操作
  预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题。
  只传参数，比传递 SQL 语句更高效。
  相同语句可以一次解析，多次使用，提高处理效率。
  4. 【强制】禁止使用 SELECT * 必须使用 SELECT <字段列表> 查询
  a. 消耗更多的 CPU 和 IO 以网络带宽资源
  b. 无法使用覆盖索引
  c. 可减少表结构变更带来的影响
  5. 【推荐】避免使用子查询
  通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。
  子查询性能差的原因：
  子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。
  由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。
  6. 【推荐】避免使用 JOIN 关联太多的表
  对于 MySQL 来说，是存在关联缓存的，缓存的大小可以由 join_buffer_size 参数进行设置。
  在 MySQL 中，对于同一个 SQL 多关联（join）一个表，就会多分配一个关联缓存，如果在一个 SQL 中关联的表越多，所占用的内存也就越大。
  如果程序中大量的使用了多表关联的操作，同时 join_buffer_size 设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。
  同时对于关联操作来说，会产生临时表操作，影响查询效率，MySQL 最多允许关联 61 个表，建议不超过 5 个。
  7. 【建议】减少同数据库的交互次数
  减少网络传输次数
  数据库更适合处理批量操作，合并多个相同的操作到一起，可以提高处理效率。
  8. 【推荐】in的数量限制
  in 的值不要超过 500 个，in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。
  9. 【推荐】WHERE 从句中禁止对列进行函数转换和计算，以免使索引失效问题
  ```
  # 无法使用索引
  where date(create_time)='20190101'
  # 可以使用索引
  # where create_time >= '20190101' and create_time < '20190102'
  ```
- 索引设计规范
  100. 【建议】限制每张表上的索引数量,建议单张表索引不超过 5 个
  索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。
  因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。
  101. 【推荐】常见索引列建议
  a. 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列
  b. 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段
  c. 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好
  d. 多表 join 的关联列
  102. 【推荐】如何选择索引列的顺序
  a. 区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）
  b. 尽量把字段长度小的列放在联合索引的左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好???）
  c. 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引???）
  103. 【建议】频繁的查询优先考虑使用覆盖索引
  覆盖索引：就是包含了所有查询字段 (where,select,order by,group by 包含的字段) 的索引
  例如: select id from t where id>5 order by id desc;
  覆盖索引的好处：
  a. 避免 Innodb 表进行索引的二次查询: Innodb 是以聚集索引的顺序来存储的，对于 Innodb 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。
  b. 可以把随机 IO 变成顺序 IO 加快查询效率: 由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。
- 数据库设计设计规范
  200. 【强制】所有表必须使用 Innodb 存储引擎
- 表设计规范
  300. 【推荐】使用utf8mb4编码方式
  301.【强制】不得使用外键与级联，一切外键概念必须在应用层解决。
  说明: 以学生和成绩的关系为例，学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，即为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群; 级联更新是强阻塞，存在数据库更新风暴的风 险; 外键影响数据库的插入速度
  ---阿里巴巴开发手册
  对分库分表不友好 ：因为分库分表下外键是无法生效的。
  302. 【强制】在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键。
- 列设计规范
  400. 【推荐】优先选择符合存储需要的最小的数据类型
  列的字段越大，建立索引时所需要的空间也就越大，这样同样一页大小中所能存储的索引节点的数量也就越少，在遍历时所需要的 IO 次数也就越多，索引的性能也就越差。
  402. 【推荐】避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据
  a. 建议把 BLOB 或是 TEXT 列分离到单独的扩展表中
  MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 sql 性能变得很差，但是不是说一定不能使用这样的数据类型。
  如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。
- 数据库操作行为规范
  500. 【强制】超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作
  问题:
  a. 大批量操作可能会造成严重的主从延迟
  主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间， 而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况
  b. binlog 日志为 row 格式时会产生大量的日志
  大批量写操作会产生大量日志，特别是对于 row 格式二进制数据而言，由于在 row 格式中会记录每一行数据的修改，我们一次修改的数据越多，产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因
  c. 避免产生大事务操作
  大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对 MySQL 的性能产生非常大的影响。
  特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批
  501. 【强制】对于大表使用 pt-online-schema-change 修改表结构
  a. 避免大表修改产生的主从延迟
  b. 避免在对表字段进行修改时进行锁表
  对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的。
  pt-online-schema-change工作机制 它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉。把原来一个 DDL 操作，分解成多个小的批次进行